# ğŸ¬ Movie Recommender (GPU + MLOps Pipeline)

This project demonstrates an end-to-end **AI/ML workflow** using containerized services for training, tracking, and serving a movie recommendation model.

## ğŸ§© Architecture Overview

dataset â†’ trainer (PyTorch, GPU)
â†’ MLflow (experiment tracking)
â†’ BentoML (model packaging & inference on GPU)
â†’ backend API (FastAPI)
â†’ pgvector (vector storage)

All services are orchestrated via **Docker Compose**.

## ğŸš€ Main Components

- **backend/** â€“ FastAPI service providing `/recommend` endpoint  
- **trainer/** â€“ PyTorch model trainer with MLflow tracking  
- **mlflow/** â€“ Experiment and model tracking server  
- **bento/** â€“ BentoML service for model inference  
- **db (pgvector)** â€“ Stores movie embeddings for similarity search  

## ğŸ’¡ Example Usage

```bash
$ curl -X POST "http://localhost:8000/recommend?limit=5" \
  -H "Content-Type: application/json" \
  -d '{
    "user_ratings": {
      "ratings": {
        "14": 5,
        "12": 5,
        "64": 5,
        "345": 5
      }
    }
  }'
```

Response:
```
[{"movie_id":1025,"similarity":0.3218059241771698},{"movie_id":769,"similarity":
0.31998586654663086},{"movie_id":370,"similarity":0.3095213359309045},{"movie_id
":1265,"similarity":0.3009481430053711},{"movie_id":938,"similarity":0.300668427
36805777}]

```


## âš™ï¸ Key Features
* GPU-accelerated training with PyTorch
* MLflow tracking for metrics and artifacts
* pgvector-based embedding search
* BentoML inference service on GPU
* Fully containerized MLOps pipeline
